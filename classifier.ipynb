{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(sheet, i):\n",
    "    filename = sheet[\"C\" + str(i)].value\n",
    "    filename.replace(\" \", \"\")\n",
    "    number_of_dashes = filename.count(\"-\")\n",
    "    if number_of_dashes == 5 or number_of_dashes == 4:\n",
    "        number = filename.split(\"-\")[4]\n",
    "    else:\n",
    "        number = \"\"\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_number(sheet):\n",
    "    number_list = []\n",
    "    for i in range(2, sheet.max_row):\n",
    "        number = extract_number(sheet, i)\n",
    "        if len(number) == 6:\n",
    "            number_list.append(number)\n",
    "    return number_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = load_workbook(filename=\"Lead Monitoring Report  (52).xlsx\")\n",
    "sheet = workbook.active\n",
    "numbers_list = find_number(sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_words(df):\n",
    "    n_grams = df[\"n-gram\"].tolist()\n",
    "    unique_n_grams = list(dict.fromkeys(n_grams))\n",
    "    return unique_n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_words(df):\n",
    "    words_per_file = dict()\n",
    "    for i in range(1, 186):\n",
    "        n_grams = df[\"n-gram\"][df.filecount == i].tolist()\n",
    "        frequencies = df[\"frequency\"][df.filecount == i].tolist()\n",
    "        filenames = df[\"filename\"][df.filecount == i].tolist()\n",
    "        number = filenames[0].split(\"-\")[4][0:6]\n",
    "        words_per_file[number] = [(n_grams[j], frequencies[j]) for j in range(len(n_grams))]\n",
    "    return words_per_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"output.csv\")\n",
    "words_list = vectorize_words(df)\n",
    "words_and_frequencies = organize_words(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_files = list(set(numbers_list).intersection(words_and_frequencies.keys()))\n",
    "words_dict = {}\n",
    "for file_number in words_and_frequencies.keys():\n",
    "    if file_number in common_files:\n",
    "        words_dict[file_number] = words_and_frequencies[file_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_names(sheet, column, numbers_list):\n",
    "    big_name_list = []\n",
    "    encodings_dict = dict()\n",
    "    for i in range(2, sheet.max_row):\n",
    "        names = sheet[column + str(i)].value\n",
    "        names = names.replace(\",\", \", \")\n",
    "        names = names.split(\"/\")[1]\n",
    "        x = re.findall(\"\\d+\", names)\n",
    "        if (x):\n",
    "            total = re.split('\\d+', names)[1]\n",
    "        else:\n",
    "            continue\n",
    "        total = total.replace(\") \", \"\")\n",
    "        name_list = total.split(\", \")\n",
    "        name_list = [name.lower() for name in name_list]\n",
    "        name_list = [name.lstrip() for name in name_list]\n",
    "        file_number = extract_number(sheet, i)\n",
    "        if file_number in numbers_list:\n",
    "            big_name_list += name_list\n",
    "            encodings_dict[file_number] = name_list\n",
    "        \n",
    "    final_list = list(dict.fromkeys(big_name_list))\n",
    "    final_list = sorted(final_list)\n",
    "    return final_list[1:], encodings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_encode_numbers(lst, dct):\n",
    "    for key in dct.keys():\n",
    "        dct[key] = [1 if i in dct[key] else 0 for i in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_list, R_dict = vectorize_names(sheet, \"Q\", common_files)\n",
    "LR_list, LR_dict = vectorize_names(sheet, \"R\", common_files)\n",
    "OLR_list, OLR_dict = vectorize_names(sheet, \"S\", common_files)\n",
    "\n",
    "hot_encode_numbers(R_list, R_dict)\n",
    "hot_encode_numbers(LR_list, LR_dict)\n",
    "hot_encode_numbers(OLR_list, OLR_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_encode_words(words_list, words_per_file):\n",
    "    encoding = dict()\n",
    "    i=1\n",
    "    for number in words_per_file.keys():\n",
    "        for pair in words_per_file[number]:\n",
    "            if number not in encoding.keys():\n",
    "                encoding[number] = np.zeros(len(words_list))\n",
    "            encoding[number][words_list.index(pair[0])] = pair[1]\n",
    "        print(i)\n",
    "        i+=1\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_encoding = hot_encode_words(words_list, words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_encodings(numbers_encoding, words_encoding):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for n1 in numbers_encoding.keys():\n",
    "        for n2 in words_encoding.keys():\n",
    "            if n1 == n2:\n",
    "                X.append(words_encoding[n2])\n",
    "                Y.append(numbers_encoding[n1])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = match_encodings(R_dict, words_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data.pickle\", 'wb') as f:\n",
    "    pickle.dump([X, Y], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "with open('data.pickle', 'rb') as f:\n",
    "    X, Y = pickle.load(f)\n",
    "\n",
    "df_X = pd.DataFrame(X)\n",
    "dfY = pd.DataFrame(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_deleted = []\n",
    "for i in range(dfY.shape[1]):\n",
    "    count = 0\n",
    "    for y in Y:\n",
    "        count += y[i]\n",
    "    if count < 10:\n",
    "        to_be_deleted.append(i)\n",
    "        \n",
    "df_Y = dfY.drop(to_be_deleted, axis=1)\n",
    "df_Y.columns = range(df_Y.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = pd.DataFrame(R_list)\n",
    "names_list = names_list.drop(to_be_deleted).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from random import sample\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "\n",
    "no_of_people = df_Y.shape[1]\n",
    "X_train, X_test = [[] for i in range(no_of_people)], [[] for i in range(no_of_people)]\n",
    "Y_train, Y_test = [[] for i in range(no_of_people)], [[] for i in range(no_of_people)]\n",
    "total = df_Y.shape[0]\n",
    "test_portion = round(total * 0.3)\n",
    "for i in range(no_of_people):\n",
    "    k = 0\n",
    "    for j in range(total):\n",
    "        if df_Y.iloc[j][i] == 1 or total - j <= test_portion - k:\n",
    "            Y_test[i].append(df_Y.iloc[j].tolist()[i])\n",
    "            X_test[i].append(df_X.iloc[j])\n",
    "            k += 1\n",
    "        else:\n",
    "            Y_train[i].append(df_Y.iloc[j])\n",
    "            X_train[i].append(df_X.iloc[j])\n",
    "        if k == 3:\n",
    "            indices = np.arange(j + 1, df_Y.shape[0])\n",
    "            test_indices = sample(list(indices), test_portion - 3)\n",
    "            for z in range(j + 1, df_Y.shape[0]):\n",
    "                if z in test_indices:\n",
    "                    Y_test[i].append(df_Y.iloc[z].tolist()[i])\n",
    "                    X_test[i].append(df_X.iloc[z])\n",
    "                else:\n",
    "                    Y_train[i].append(df_Y.iloc[z])\n",
    "                    X_train[i].append(df_X.iloc[z])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = []\n",
    "models = {}\n",
    "for i in range(no_of_people):\n",
    "    x_train = X_train[i]\n",
    "    y_train = [y[i] for y in Y_train[i]]\n",
    "    if sum(y_train) == 0:\n",
    "        Y_pred.append(np.array([0 for y in range(26)]))\n",
    "        print(\"noooo\")\n",
    "        continue\n",
    "    models[i] = sgd.fit(x_train, y_train)\n",
    "    y_pred = models[i].predict(X_test[i])\n",
    "    Y_pred.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_transposed = [*zip(*Y_pred)]\n",
    "Y_test_transposed = [*zip(*Y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.54      0.61        13\n",
      "           1       0.88      1.00      0.94        22\n",
      "           2       0.80      1.00      0.89        20\n",
      "           3       0.91      0.77      0.83        13\n",
      "           4       0.88      1.00      0.94        22\n",
      "           5       0.71      0.62      0.67        16\n",
      "           6       0.73      0.58      0.65        19\n",
      "           7       0.56      0.45      0.50        11\n",
      "           8       0.71      0.77      0.74        13\n",
      "           9       0.62      0.42      0.50        12\n",
      "          10       1.00      0.36      0.53        11\n",
      "          11       0.75      0.33      0.46         9\n",
      "          12       1.00      0.18      0.31        11\n",
      "          13       0.62      0.50      0.56        10\n",
      "          14       0.84      0.80      0.82        20\n",
      "          15       0.96      1.00      0.98        24\n",
      "          16       0.92      1.00      0.96        23\n",
      "          17       0.67      0.67      0.67         9\n",
      "          18       0.75      0.60      0.67        10\n",
      "          19       0.60      0.43      0.50         7\n",
      "          20       0.83      0.56      0.67         9\n",
      "          21       0.96      0.96      0.96        24\n",
      "          22       0.56      0.82      0.67        11\n",
      "          23       0.52      0.92      0.67        12\n",
      "          24       0.00      0.00      0.00         8\n",
      "          25       1.00      0.12      0.22         8\n",
      "          26       1.00      0.25      0.40        16\n",
      "          27       0.00      0.00      0.00         6\n",
      "          28       0.73      0.94      0.82        17\n",
      "          29       1.00      0.20      0.33        10\n",
      "          30       0.67      0.44      0.53         9\n",
      "          31       0.88      0.50      0.64        14\n",
      "          32       0.00      0.00      0.00         6\n",
      "          33       0.67      0.31      0.42        13\n",
      "          34       0.91      0.91      0.91        23\n",
      "          35       0.75      0.55      0.63        11\n",
      "          36       1.00      0.45      0.62        11\n",
      "          37       0.67      0.46      0.55        13\n",
      "          38       0.83      0.42      0.56        12\n",
      "          39       0.60      0.38      0.46         8\n",
      "          40       0.80      0.29      0.42        14\n",
      "          41       0.85      0.79      0.81        14\n",
      "          42       1.00      0.17      0.29         6\n",
      "          43       0.00      0.00      0.00         4\n",
      "          44       0.62      0.38      0.48        13\n",
      "          45       0.00      0.00      0.00         3\n",
      "          46       0.00      0.00      0.00         8\n",
      "          47       1.00      0.31      0.47        13\n",
      "          48       0.62      1.00      0.77        15\n",
      "          49       0.86      0.50      0.63        12\n",
      "          50       0.67      0.44      0.53         9\n",
      "          51       0.00      0.00      0.00        10\n",
      "          52       1.00      0.40      0.57        10\n",
      "          53       0.56      0.45      0.50        11\n",
      "          54       0.67      0.22      0.33         9\n",
      "          55       0.78      0.50      0.61        14\n",
      "          56       0.50      0.50      0.50        12\n",
      "\n",
      "   micro avg       0.77      0.59      0.67       713\n",
      "   macro avg       0.69      0.49      0.54       713\n",
      "weighted avg       0.75      0.59      0.62       713\n",
      " samples avg       0.77      0.65      0.68       713\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\efeha\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
    "Y_pred_list = [p.tolist() for p in Y_pred]\n",
    "print('accuracy %s' % accuracy_score(Y_pred_transposed, Y_test_transposed))\n",
    "print(classification_report(Y_test_transposed, Y_pred_transposed))\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(Y_test_transposed, Y_pred_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════════════════╤═════════════╤══════════╤════════════╤═══════════╕\n",
      "│ name                   │   precision │   recall │   f1-score │   support │\n",
      "╞════════════════════════╪═════════════╪══════════╪════════════╪═══════════╡\n",
      "│ eda teki̇roğlu          │    0.96     │ 1        │   0.979592 │        24 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ evren eki̇nci̇           │    0.958333 │ 0.958333 │   0.958333 │        24 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ ekin eki̇z              │    0.92     │ 1        │   0.958333 │        23 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ mehmet emin karaaslan  │    0.913043 │ 0.913043 │   0.913043 │        23 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ ahmet ergin efendi̇oğlu │    0.88     │ 1        │   0.93617  │        22 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ ali volkan debbağ      │    0.88     │ 1        │   0.93617  │        22 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ akif bakan             │    0.8      │ 1        │   0.888889 │        20 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ douglas london         │    0.842105 │ 0.8      │   0.820513 │        20 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ antidio magnani        │    0.733333 │ 0.578947 │   0.647059 │        19 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ john hooper            │    0.727273 │ 0.941176 │   0.820513 │        17 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ andrew johnson         │    0.714286 │ 0.625    │   0.666667 │        16 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ harun kirmaci          │    1        │ 0.25     │   0.4      │        16 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ taha enes kon          │    0.625    │ 1        │   0.769231 │        15 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ levent kiliç           │    0.875    │ 0.5      │   0.636364 │        14 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ rob preston            │    0.8      │ 0.285714 │   0.421053 │        14 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ sabahattin kulu        │    0.846154 │ 0.785714 │   0.814815 │        14 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ özgür göral            │    0.777778 │ 0.5      │   0.608696 │        14 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ adil gürkan ceyhan     │    0.7      │ 0.538462 │   0.608696 │        13 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ ali murat gürkan       │    0.909091 │ 0.769231 │   0.833333 │        13 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ beyhan gören           │    0.714286 │ 0.769231 │   0.740741 │        13 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ mehmed emre kaya       │    0.666667 │ 0.307692 │   0.421053 │        13 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ melih gökmen           │    0.666667 │ 0.461538 │   0.545455 │        13 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ selen yeşildal         │    0.625    │ 0.384615 │   0.47619  │        13 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ suling zhai            │    1        │ 0.307692 │   0.470588 │        13 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ borahan cönkeroğlu     │    0.625    │ 0.416667 │   0.5      │        12 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ frederic mckinnon      │    0.52381  │ 0.916667 │   0.666667 │        12 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ nurettin demi̇rdöven    │    0.833333 │ 0.416667 │   0.555556 │        12 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ tanmoy dutta           │    0.857143 │ 0.5      │   0.631579 │        12 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ şebnem koçoğlu bi̇lgi̇n  │    0.5      │ 0.5      │   0.5      │        12 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ berke tarakçioğlu      │    0.555556 │ 0.454545 │   0.5      │        11 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ can boğa               │    1        │ 0.363636 │   0.533333 │        11 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ chris sharratt         │    1        │ 0.181818 │   0.307692 │        11 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ fatih kalyoncu         │    0.5625   │ 0.818182 │   0.666667 │        11 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ mehmet parlar          │    0.75     │ 0.545455 │   0.631579 │        11 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ mehmet çi̇çek           │    1        │ 0.454545 │   0.625    │        11 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ yazgı akin             │    0.555556 │ 0.454545 │   0.5      │        11 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ cumhur dervi̇şoğlu      │    0.625    │ 0.5      │   0.555556 │        10 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ emir önal              │    0.75     │ 0.6      │   0.666667 │        10 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ kian chung beh         │    1        │ 0.2      │   0.333333 │        10 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ tolga yurteri          │    0        │ 0        │   0        │        10 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ utku arkın durdu       │    1        │ 0.4      │   0.571429 │        10 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ ceren arslan           │    0.75     │ 0.333333 │   0.461538 │         9 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ elif yildirim          │    0.666667 │ 0.666667 │   0.666667 │         9 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ erkan i̇nce             │    0.833333 │ 0.555556 │   0.666667 │         9 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ köksal çiğ             │    0.666667 │ 0.444444 │   0.533333 │         9 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ tolga demi̇r            │    0.666667 │ 0.444444 │   0.533333 │         9 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ çağlar çakiroğlu       │    0.666667 │ 0.222222 │   0.333333 │         9 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ hakan keskin           │    0        │ 0        │   0        │         8 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ harry cotton           │    1        │ 0.125    │   0.222222 │         8 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ oğuzhan kılıç          │    0.6      │ 0.375    │   0.461538 │         8 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ suat aktepe            │    0        │ 0        │   0        │         8 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ enver gümüş            │    0.6      │ 0.428571 │   0.5      │         7 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ james heduvan          │    0        │ 0        │   0        │         6 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ martin coe             │    0        │ 0        │   0        │         6 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ sait satar             │    1        │ 0.166667 │   0.285714 │         6 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ salih karakaya         │    0        │ 0        │   0        │         4 │\n",
      "├────────────────────────┼─────────────┼──────────┼────────────┼───────────┤\n",
      "│ serhat pişen           │    0        │ 0        │   0        │         3 │\n",
      "╘════════════════════════╧═════════════╧══════════╧════════════╧═══════════╛\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "data = [names_list[0].tolist(), precision, recall, fscore, support]\n",
    "transpose = np.transpose(data)\n",
    "final = sorted(transpose, key=lambda x: int(x[4]), reverse=True)\n",
    "table = tabulate(final, headers = [\"name\", \"precision\", \"recall\", \"f1-score\", \"support\"], tablefmt=\"fancy_grid\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame(transpose)\n",
    "precision = {}\n",
    "recall = {}\n",
    "f1 = {}\n",
    "\n",
    "for i in range(25, 3, -1):\n",
    "    prec = df_data[support == i][1]\n",
    "    rec = df_data[support == i][2]\n",
    "    f = df_data[support == i][3]\n",
    "    if len(prec) != 0:\n",
    "        average_prec = sum([float(p) for p in prec]) / len(prec)\n",
    "        precision[i] = average_prec\n",
    "        \n",
    "        average_rec = sum([float(p) for p in rec]) / len(rec)\n",
    "        recall[i] = average_rec\n",
    "        \n",
    "        average_f = sum([float(p) for p in f]) / len(f)\n",
    "        f1[i] = average_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2265759e910>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn\n",
    "\n",
    "x_pre = np.array(list(precision.keys()))\n",
    "y_pre = np.array(list(precision.values()))\n",
    "\n",
    "x_rec = np.array(list(recall.keys()))\n",
    "y_rec = np.array(list(recall.values()))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x_pre,y_pre)\n",
    "plt.plot(x_rec,y_rec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
